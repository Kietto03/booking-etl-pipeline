import pandas as pd
from datetime import datetime, timedelta
from playwright.sync_api import sync_playwright
import time
import random
from sqlalchemy import create_engine, text

# --- C·∫§U H√åNH DATABASE ---
# B·∫°n thay ƒë·ªïi th√¥ng tin n√†y cho ƒë√∫ng v·ªõi m√°y c·ªßa b·∫°n
DB_USER = 'postgres'
DB_PASS = 'kiet'  # Thay password c·ªßa b·∫°n
DB_HOST = 'localhost'
DB_PORT = '5432'
DB_NAME = 'booking_db'

# --- C·∫§U H√åNH ---
LIMIT_DAYS = 3       
LIMIT_GROUPS = 2     
LIMIT_ITEMS = 5      
HEADLESS_MODE = False  # <--- S·ª¨A TH√ÄNH FALSE ƒê·ªÇ HI·ªÜN TR√åNH DUY·ªÜT

def generate_url(city, check_in_date, group_config):
    check_in_str = check_in_date.strftime("%Y-%m-%d")
    check_out_str = (check_in_date + timedelta(days=1)).strftime("%Y-%m-%d")
    city_encoded = city.replace(" ", "+") 
    base_url = f"https://www.booking.com/searchresults.vi.html?ss={city_encoded}&checkin={check_in_str}&checkout={check_out_str}&group_adults={group_config['a']}&group_children={group_config['c']}&no_rooms={group_config['r']}"
    return base_url

def crawl_data():
    cities = ["Da Nang", "Hue"]
    
    all_groups = [
        {'id': '1_adult', 'a': 1, 'c': 0, 'r': 1}, 
        {'id': '2_adults', 'a': 2, 'c': 0, 'r': 1},
        {'id': '2_adults_1_child', 'a': 2, 'c': 1, 'r': 1},
        {'id': '2_adults_2_children', 'a': 2, 'c': 2, 'r': 2},
    ]
    groups = all_groups[:LIMIT_GROUPS] 
    
    start_date = datetime(2025, 6, 20)
    date_list = [start_date + timedelta(days=x) for x in range(LIMIT_DAYS)]
    
    all_results = []
    print(f"üöÄ B·∫Øt ƒë·∫ßu Crawl (Hi·ªán browser ƒë·ªÉ debug)...")

    with sync_playwright() as p:
        # Launch browser c√≥ header gi·∫£ l·∫≠p
        browser = p.chromium.launch(headless=HEADLESS_MODE, args=['--start-maximized']) # M·ªü r·ªông c·ª≠a s·ªï
        
        # T·∫°o context v·ªõi User Agent x·ªãn (Gi·∫£ l√†m Chrome tr√™n Windows 10)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            viewport={'width': 1280, 'height': 720}
        )
        page = context.new_page()

        # --- T·∫†M T·∫ÆT CH·∫∂N ·∫¢NH ƒê·ªÇ ƒê·∫¢M B·∫¢O LOAD ƒê∆Ø·ª¢C DATA TR∆Ø·ªöC ---
        # (Khi code ch·∫°y ngon r·ªìi m·ªõi b·∫≠t l·∫°i ƒë·ªÉ t·ªëi ∆∞u sau)
        # page.route("**/*", route_intercept) 
        # --------------------------------------------------------

        for city in cities:
            for check_in in date_list:
                for group in groups:
                    
                    full_url = generate_url(city, check_in, group)
                    print(f"--> {city} | {check_in.date()} | {group['id']}...", end=" ", flush=True)
                    
                    try:
                        page.goto(full_url, timeout=60000, wait_until="domcontentloaded")
                        
                        # TƒÉng th·ªùi gian ch·ªù selector l√™n 10s (m·∫°ng ch·∫≠m ho·∫∑c c·∫ßn load JS)
                        try:
                            page.wait_for_selector('[data-testid="property-card"]', timeout=10000)
                        except:
                            # N·∫øu kh√¥ng th·∫•y th·∫ª ph√≤ng, c√≥ th·ªÉ do hi·ªán CAPTCHA ho·∫∑c trang l·ªói
                            print("‚ùå (Timeout/Captcha?)")
                            # Ch·ª•p ·∫£nh l·ªói ƒë·ªÉ debug n·∫øu c·∫ßn
                            # page.screenshot(path=f"error_{city}_{check_in.date()}.png")
                            continue

                        cards = page.locator('[data-testid="property-card"]').all()
                        
                        count_local = 0
                        for card in cards:
                            if count_local >= LIMIT_ITEMS: break 

                            try:
                                link = card.locator('[data-testid="title-link"]').get_attribute("href")
                                address = card.locator('[data-testid="address"]').inner_text()
                                
                                price_locator = card.locator('[data-testid="price-and-discounted-price"]').first
                                if price_locator.count() > 0:
                                    price_raw = price_locator.inner_text()
                                    price_clean = float(price_raw.replace('VND', '').replace('.', '').replace(',', '').strip())
                                else:
                                    price_clean = 0
                                
                                all_results.append({
                                    'link': link.split('?')[0],
                                    'address': address,
                                    'city': city,
                                    'price': price_clean,
                                    'check_in_date': check_in.date(),
                                    'group_option': group['id'],
                                    'scanned_at': datetime.now().date()
                                })
                                count_local += 1
                            except:
                                continue 
                        
                        print(f"‚úÖ L·∫•y {count_local} m·ª•c.")

                    except Exception as e:
                        print(f"‚ùå Error: {str(e)[:50]}...")
                    
                    # Ngh·ªâ l√¢u h∆°n ch√∫t ƒë·ªÉ gi·ªëng ng∆∞·ªùi th·∫≠t
                    time.sleep(2) 

        browser.close()

    print(f"üéâ Ho√†n t·∫•t! T·ªïng c·ªông: {len(all_results)} b·∫£n ghi.")
    return pd.DataFrame(all_results)

# --- H√ÄM L∆ØU V√ÄO DB (Load Staging) ---
def run_crawler_and_load_staging():
    # 1. Crawl d·ªØ li·ªáu
    df = crawl_data()
    
    if df.empty:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c qu√©t.")
        return

    # 2. K·∫øt n·ªëi DB
    connection_string = f'postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}'
    engine = create_engine(connection_string)

    # 3. Insert v√†o b·∫£ng booking_staging
    with engine.connect() as conn:
        # --- S·ª¨A ·ªû ƒê√ÇY ---
        # B·ªçc c√¢u l·ªánh SQL trong h√†m text()
        conn.execute(text("TRUNCATE TABLE booking_staging;"))
        conn.commit() # <--- QUAN TR·ªåNG: Ph·∫£i commit th√¨ l·ªánh m·ªõi c√≥ hi·ªáu l·ª±c
        print("ƒê√£ l√†m s·∫°ch b·∫£ng booking_staging.")
        
    df.to_sql('booking_staging', engine, if_exists='append', index=False)
    print("‚úÖ ƒê√£ ƒë·∫©y d·ªØ li·ªáu v√†o b·∫£ng booking_staging th√†nh c√¥ng.")

if __name__ == "__main__":
    run_crawler_and_load_staging()